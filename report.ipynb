{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our goal in this project is to examine different search strategies and find out how each algorithm complies with our problem and which one will yield a better result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Formulation and State-Space Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When defining the environment states, we only need to keep track of the features we need in order to solve the problem. So in this problem only coordinates of the person and boxes change from our actions, therefor we only need to store these values.  \n",
    "\n",
    "Another disadvantage of storing the whole map can be unnecessary additional memory overhead when the environment states change.  \n",
    "\n",
    "**Technically speaking, search state is an abstraction of our world state.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uninformed Search Algorithms: Concepts and Properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the state definition from the previous section, we can define actions as means to change the coordinates of Mike (our searcher which is indicated as H) in the map.\n",
    "\n",
    "Therefor, having two-dimensional map in this problem means we have 4 directions for Mike to go : up, down, left and right.   \n",
    "**For simplicity we can indicate these actions by a single character :**\n",
    "**U, D, L, R.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparative Analysis of Breadth-First Search and Depth-First Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actions as discussed in the previous section is indicated by U, D, L and R.  \n",
    "For each action we define our transition model so that according to the walls and portals and boxes location, it switches to another state which has a different person coordinates and maybe box coordinates as well.  \n",
    "We can use pre-stored walls and portals and other useful data to implement the transition model. (conditions and rules)  \n",
    "Goal states are the states at which the boxes are placed on their appropriate corresponding point in our map. (using conditions)  \n",
    "Initial state can be extracted from the initial world state map using initial mike and boxes location. Which we choose the initial mike location as our start point and proceed from there.    \n",
    "Later in A* algorithm we have to define a utility or cost function that examines each action, enabling us to finally choose between them based on it.  \n",
    "All legal actions have the same cost. (uniform)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterative Deepening Search: Motivation and Algorithmic Trade-offs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we defined our environment state as some coordinates, a state could have multiple paths to reach to and we can have repetitive states during the search.  \n",
    "To fix this issue we can use a visited set that stores the states we have seen so far during the search and only expand the unvisited states. Because otherwise we could be stuck in loops (mainly DFS) or lose efficiency (time and storage overhead for duplicate nodes).  \n",
    "Later in A* algorithm using a cost function and heuristic function we can maintain efficiency within search by choosing somewhat optimal states to expand from the frontier states (or the fringe)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theoretical Expectations for Search Algorithm Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BFS\n",
    "This algorithm performs breadth-first search which on the plus side is **complete and optimal** but it takes more time in comparison to informed search algorithms and becuase it has to store a full search tree level in its queue it has a hight space complexity, so in cases where the goal state is located far in the depths of the search tree, this algorithm may take ages to respond and its insufficient.  \n",
    "### DFS\n",
    "This algorithm performs depth-first search which on the plus side it stores fewer states in its stack comparing to BFS and in cases where the number of goal states are high, and are located deep in the search tree, it can find a goal state in less time, but the catch is that it wont work every time, **its not optimal** and it might take a huge amount of time.  \n",
    "### IDS\n",
    "BFS gives the optimal solution but it takes a lot of space, on the other hand DFS performs with less storage requierd and quickly scans through the depths of the search tree.  \n",
    "Combining these two strategies we obtain IDS or iterative-deepening search where we constantly perform dfs with a depth limit that is incremented after each DFS if the solution hasn't been found.  \n",
    "This method ensures that we reach an optimal solution because we are scaning layar by layar and the goal state with lowest depth will be found first.  The trade off is that it will take much more time than DFS and BFS but it will be space-efficient.\n",
    "### A*\n",
    "Unlike previous methods, this algorithm is informed search this means that we define a hueristic function that is a performance measure which acts like a cost function for each state and gives a value corresponding to it.  \n",
    "In other words we use our knowledge of the environment to come up with a hueristic functions that for each action it gives a virtual cost and we can then take the minimum huristic + cost to reach that specific state.  \n",
    "Having a consistent hueristic function in this problem ensures that we reach optimal solution (and admissible heuristic function for problems with no loops in their state graph).  \n",
    "### Weighted A*\n",
    "Using a constant to multiply heuristic function we lose the optimality but we gain more efficient searchs with less time taken to reach the goal.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Empirical Evaluation of Uninformed Search Algorithms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having implemented BFS, DFS and IDS algorithms, we can observe that the results comply with our assumptions in section 5.  \n",
    "In all test cases DFS algorithm has offered a solution with longer action sequence whearas all BFS answers are optimal with least possible moves.  \n",
    "\n",
    "In cases where there are a lot of paths to reach goal states, DFS explores less states than BFS but in more complex and bigger maps DFS explores more states to reach a goal state, because it just wastefully goes around the map therefor DFS takes a lot more time compared to BFS and its overall inefficient and in some cases it may take a huge time that its practically impossible to wait for the solution.  \n",
    "\n",
    "IDS is based on a lot of DFS, so as a result it will explore a lot of states compared to DFS and BFS therefor it will take more time than BFS, but its better than DFS because for complex cases it might work with less time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heuristic Design and Theoretical Analysis for Informed Search\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In naive heuristic function we just calculate the manhattan distance between player and box and then add it to the manhattan distance of the specific box to its corresponding goal place.  However this method is inefficient because it doesn't take portals into account and it might produce false perceptions about the environment. For this reason we need to first of all consider portal usage in our hueristic function and secondly decide where to take minimum and where to take sums.  \n",
    "\n",
    "For example an improved version of the naive heuristic can be to focus in the closest box to the player, in other words take minimum of the manhattan distances from the player to all boxes.  Finally add the result into the manhattan distance of all boxes to their goals.  \n",
    "This yields a better result.  But it is still not consistent nor admissible because we haven't taken portal travels into consideration.  \n",
    "\n",
    "In order to solve this issue we implement a function that uses portals locations to calculate the distances with portal travels with different conditions (how ever number of portals used is considered).  \n",
    "\n",
    "This method drastically improves our hueristic function and make it both admissible and consistent.  \n",
    "Its obvious that it's admissible because we are taking the minimum distance to the nearest box and then minimum distance that boxes can go to reach their spot. So it's less then the actual cost.  \n",
    "\n",
    "For proving the consistancy take a random action for instance.  If it doesn't move any boxes the distance from boxes to their spot won't change after the move and we will either be 1 step closer to the nearest box or no changes this means our cost will be calculated at most 1 which is the actual cost of the action.  If the action causes a box to move, before and after the action we are one block away from the nearest box and we have at most moved the box 1 step closer to it's spot, So this proves that in this case our heuristic cost will be at most 1. And this proves consistancy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparative Analysis of A* Search with Different Heuristics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the A* algorithm with different heuristic functions, I had to try a lot of ways to improve it's effectiveness.  A lot of trials and errors. These are some results i've captured :  \n",
    "\n",
    "Taking minimum from distances will shift our huristic funtion towards consistancy and being able to find the optimal solution but it makes it slower to find these solutions.  Another method is to take sums from all the distances this acts the exact oposite because the larger the heuristic the more likely it will fail to yeild the optimal solution but it will find a solution a lot quicker. This is the exact principle of weighted A*. By losing consistancy we won't get optimal solutions but we can get answers a lot faster.  \n",
    "\n",
    "After trials and examining result and finding an optimal heuristic the results show that naive hueristic takes considerable more time than efficient heuristic and also in some cases it's slower than BFS.  \n",
    "\n",
    "Our optimal heuristic is fast and also finds the optimal solution except for map 9.  Using a constant of 4.5 for weighted A* we can achieve solutions (not particularly optimal) extremely fast even for map 9.  \n",
    "\n",
    "Finding the optimal constant for weighted A* is also via trial and error. At some point increasing the constant will effect the time negatively, thats the point we have to stop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Results With Different Algorithms And Weighted A* with 4.5 constant  \n",
    "A* took 0.01 seconds on map 8 and visited 292 states.  \n",
    "24 moves were used: URURDDDDLDRRRRRURDRDLDLU  \n",
    "BFS took 0.0 seconds on map 1 and visited 44 states.  \n",
    "7 moves were used: UDDULRR  \n",
    "IDS took 0.0 seconds on map 1 and visited 168 states.  \n",
    "7 moves were used: RLLRDUU  \n",
    "A* took 0.0 seconds on map 1 and visited 22 states.  \n",
    "7 moves were used: UDDULRR  \n",
    "BFS took 0.0 seconds on map 2 and visited 21 states.  \n",
    "6 moves were used: LUDDUL  \n",
    "IDS took 0.0 seconds on map 2 and visited 63 states.  \n",
    "6 moves were used: LLRDUU  \n",
    "A* took 0.0 seconds on map 2 and visited 15 states.  \n",
    "6 moves were used: LUDDUL  \n",
    "BFS took 0.0 seconds on map 3 and visited 122 states.  \n",
    "13 moves were used: ULDDUUUURDDDD  \n",
    "IDS took 0.01 seconds on map 3 and visited 602 states.  \n",
    "13 moves were used: ULDDUUUURDDDD  \n",
    "A* took 0.0 seconds on map 3 and visited 27 states.  \n",
    "13 moves were used: ULDDUUUURDDDD  \n",
    "BFS took 0.0 seconds on map 4 and visited 2 states.  \n",
    "No Solution Found!  \n",
    "IDS took 0.0 seconds on map 4 and visited 5 states.  \n",
    "No Solution Found!  \n",
    "A* took 0.0 seconds on map 4 and visited 2 states.  \n",
    "No Solution Found!  \n",
    "BFS took 0.09 seconds on map 5 and visited 6328 states.  \n",
    "15 moves were used: ULDDRDLLLUUURUL  \n",
    "IDS took 0.65 seconds on map 5 and visited 35694 states.  \n",
    "15 moves were used: LULDLRDRDLLULUU  \n",
    "A* took 0.0 seconds on map 5 and visited 107 states.  \n",
    "17 moves were used: LULDLDLUUDRRDRDLL  \n",
    "BFS took 0.35 seconds on map 6 and visited 17807 states.  \n",
    "34 moves were used: UUUUURRRLLLLLLLDDDDDDDDDRDLRRRRRRR  \n",
    "IDS took 9.16 seconds on map 6 and visited 375679 states.  \n",
    "34 moves were used: RRDDDDDRLLLLLLLRUUUUUUUUUULRRRRRRR  \n",
    "A* took 0.03 seconds on map 6 and visited 1236 states.  \n",
    "34 moves were used: RDDDDDRRLLLLLLLUUUUUUUUURULRRRRRRR  \n",
    "BFS took 17.22 seconds on map 7 and visited 644754 states.  \n",
    "34 moves were used: RURRDDDDLDRUUUULLLRDRDRDDLLDLLUUDR  \n",
    "IDS took 141.15 seconds on map 7 and visited 5876434 states.  \n",
    "34 moves were used: RURRDDDDLDRUUUULLLRDRDRDDLLDLLURLU  \n",
    "A* took 0.04 seconds on map 7 and visited 1672 states.  \n",
    "38 moves were used: RURRDLLLRRRDDDLDRUUUULLDRDRDDLLDLLUUDR  \n",
    "BFS took 0.12 seconds on map 8 and visited 7419 states.  \n",
    "14 moves were used: UURDLDRRDRURDR  \n",
    "IDS took 0.87 seconds on map 8 and visited 40672 states.  \n",
    "14 moves were used: UURDLDRRDRURDR  \n",
    "A* took 0.01 seconds on map 8 and visited 292 states.  \n",
    "24 moves were used: URURDDDDLDRRRRRURDRDLDLU  \n",
    "**A\\* took 0.25 seconds on map 9 and visited 7208 states.**  \n",
    "**67 moves were used: RURURDRRDRDLDLULLULURRURDLUUUUULULDLDRRURDDDDLDRDLDRRDRURULULULDLDR**  \n",
    "BFS took 5.11 seconds on map 10 and visited 241503 states.  \n",
    "46 moves were used: RRRRRDRULURULLLULDRUUULDRDLDRRDRULURURDDRDLLLL  \n",
    "A* took 0.49 seconds on map 10 and visited 8541 states.  \n",
    "46 moves were used: RRRRRDRULURULLLULLDRUULDRDLDRRDRULURURDDRDLLLL  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runtime and State-Space Complexity Comparison Across Search Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Map 1:  \n",
    "\n",
    "| Algorithm | States Visited | Solution Depth | Execution Time (s) |\n",
    "|----------|----------------|----------------|--------------------|\n",
    "| BFS | 44 | 7 | 0 |\n",
    "| DFS | 17 | 7 | 0 |\n",
    "| IDS | 128 | 7 | 0 |\n",
    "| A* | 43 | 7 | 0 |\n",
    "| Weighted A* | 22 | 7 | 0 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Map 2:  \n",
    "\n",
    "| Algorithm | States Visited | Solution Depth | Execution Time (s) |\n",
    "|----------|----------------|----------------|--------------------|\n",
    "| BFS | 21 | 6 | 0 |\n",
    "| DFS | 13 | 6 | 0 |\n",
    "| IDS | 63 | 6 | 0 |\n",
    "| A* | 21 | 6 | 0 |\n",
    "| Weighted A* | 15 | 6 | 0 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Map 3:  \n",
    "\n",
    "| Algorithm | States Visited | Solution Depth | Execution Time (s) |\n",
    "|----------|----------------|----------------|--------------------|\n",
    "| BFS | 122 | 13 | 0 |\n",
    "| DFS | 47 | 13 | 0 |\n",
    "| IDS | 602 | 13 | 0.01 |\n",
    "| A* | 92 | 13 | 0 |\n",
    "| Weighted A* | 27 | 13 | 0 |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Map 4:  \n",
    "\n",
    "| Algorithm | States Visited | Result | Execution Time (s) |\n",
    "|----------|----------------|--------|--------------------|\n",
    "| BFS | 2 | No Solution Found | 0 |\n",
    "| DFS | 2 | No Solution Found | 0 |\n",
    "| IDS | 5 | No Solution Found | 0 |\n",
    "| A* | 2 | No Solution Found | 0 |\n",
    "| Weighted A* | 2 | No Solution Found | 0 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Map 5:  \n",
    "\n",
    "| Algorithm | States Visited | Solution Depth | Execution Time (s) |\n",
    "|----------|----------------|----------------|--------------------|\n",
    "| BFS | 6325 | 15 | 0.09 |\n",
    "| DFS | 7450 | 195 | 0.13 |\n",
    "| IDS | 35694 | 15 | 0.56 |\n",
    "| A* | 1017 | 15 | 0.02 |\n",
    "| Weighted A* | 107 | 17 | 0 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Map 6:  \n",
    "\n",
    "| Algorithm | States Visited | Solution Depth | Execution Time (s) |\n",
    "|----------|----------------|----------------|--------------------|\n",
    "| BFS | 17807 | 34 | 0.32 |\n",
    "| DFS | 20497 | 749 | 0.42 |\n",
    "| IDS | 375679 | 34 | 8.19 |\n",
    "| A* | 6021 | 34 | 0.16 |\n",
    "| Weighted A* | 1236 | 34 | 0.03 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Map 7:  \n",
    "\n",
    "| Algorithm | States Visited | Solution Depth | Execution Time (s) |\n",
    "|----------|----------------|----------------|--------------------|\n",
    "| BFS | 644754 | 34 | 12.82 |\n",
    "| DFS | - | - | Time Limit |\n",
    "| IDS | - | - | Time Limit |\n",
    "| A* | 59234 | 34 | 1.95 |\n",
    "| Weighted A* | 1672 | 38 | 0.04 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Map 8:  \n",
    "\n",
    "| Algorithm | States Visited | Solution Depth | Execution Time (s) |\n",
    "|----------|----------------|----------------|--------------------|\n",
    "| BFS | 7419 | 14 | 0.12 |\n",
    "| DFS | 4551 | 313 | 0.07 |\n",
    "| IDS | 40672 | 14 | 0.6 |\n",
    "| A* | 431 | 14 | 0.02 |\n",
    "| Weighted A* | 272 | 24 | 0.01 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Map 9:  \n",
    "\n",
    "| Algorithm | States Visited | Solution Depth | Execution Time (s) |\n",
    "|----------|----------------|----------------|--------------------|\n",
    "| BFS | - | - | Time Limit |\n",
    "| DFS | - | - | Time Limit |\n",
    "| IDS | - | - | Time Limit |\n",
    "| A* | - | - | Time Limit |\n",
    "| Weighted A* (α = 4.5) | 7208 | 67 | 0.21 |\n",
    "| Weighted A* (α = 2) | 642942 | 51 | 42.95 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Map 10:  \n",
    "\n",
    "| Algorithm | States Visited | Solution Depth | Execution Time (s) |\n",
    "|----------|----------------|----------------|--------------------|\n",
    "| BFS | 241503 | 46 | 5.5 |\n",
    "| DFS | 425181 | 4532 | 14.5 |\n",
    "| IDS | - | - | Time Limit |\n",
    "| A* | 58029 | 46 | 2.85 |\n",
    "| Weighted A* | 8541 | 46 | 0.36 |\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
